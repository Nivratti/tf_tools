{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## <font color=\"#000080\" size=\"+3\">1. Setup</font>\n","metadata":{}},{"cell_type":"code","source":"!pip show tensorflow","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip show keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install --quiet keras==3.3.3\n# !pip show keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#000080\" size=\"+3\">2. Custom layer</font>\n","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras import layers\nimport tensorflow as tf\n\nclass CAM(layers.Layer):\n    \"\"\"\n    Channel Attention Module (CAM) enhances specific features across channel dimensions\n    by applying channel-wise attention mechanisms.\n\n    Attributes:\n        scale_gamma_initializer: Initializer for the scaling factor gamma.\n        scale_gamma_regularizer: Optional regularizer for the gamma weight.\n        scale_gamma_constraint: Optional constraint for the gamma weight.\n        activation_func: Name of the activation function to apply after computing attention scores ('sigmoid', 'softmax', etc.).\n    \"\"\"\n    def __init__(self, scale_gamma_initializer='zeros', scale_gamma_regularizer=None, scale_gamma_constraint=None, activation_func='sigmoid', **kwargs):\n        super(CAM, self).__init__(**kwargs)\n        self.scale_gamma_initializer = scale_gamma_initializer\n        self.scale_gamma_regularizer = scale_gamma_regularizer\n        self.scale_gamma_constraint = scale_gamma_constraint\n        self.activation_func = activation_func\n\n    def build(self, input_shape):\n        self.scale_gamma = self.add_weight(\n            shape=(1,),\n            initializer=self.scale_gamma_initializer,\n            name='scale_gamma',\n            regularizer=self.scale_gamma_regularizer,\n            constraint=self.scale_gamma_constraint\n        )\n        super(CAM, self).build(input_shape)\n\n    def call(self, inputs):\n        # Extract dynamic dimensions of the input tensor\n        batch_size, height, width, num_filters = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2], tf.shape(inputs)[3]\n\n        # Flatten the spatial dimensions and create a matrix of shape (batch_size, height*width, num_filters)\n        flattened_features = tf.reshape(inputs, (batch_size, height * width, num_filters))\n        transposed_features = tf.transpose(flattened_features, perm=[0, 2, 1])\n\n        # Compute the matrix multiplication between transposed and original feature matrix\n        channel_interaction = tf.matmul(transposed_features, flattened_features)\n\n        # Apply the selected activation function to obtain attention scores\n        if self.activation_func == 'softmax':\n            attention_scores = layers.Softmax(axis=-1)(channel_interaction)\n        elif self.activation_func == 'sigmoid':\n            attention_scores = layers.Activation('sigmoid')(channel_interaction)\n        else:\n            raise ValueError(f\"Unsupported activation function '{self.activation_func}'. Choose 'softmax', 'sigmoid', or implement additional activations.\")\n\n        # Use the attention scores to scale the original feature matrix\n        scaled_features = tf.matmul(flattened_features, attention_scores)\n        reshaped_features = tf.reshape(scaled_features, (batch_size, height, width, num_filters))\n\n        # Scale the attention-enhanced output by gamma and add back the input\n        output = self.scale_gamma * reshaped_features + inputs\n        return output\n\n    def compute_output_shape(self, input_shape):\n        return input_shape\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:06:10.688424Z","iopub.execute_input":"2024-04-27T15:06:10.688792Z","iopub.status.idle":"2024-04-27T15:06:25.054082Z","shell.execute_reply.started":"2024-04-27T15:06:10.688763Z","shell.execute_reply":"2024-04-27T15:06:25.052941Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-27 15:06:12.917854: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-27 15:06:12.917977: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-27 15:06:13.075642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input\nimport keras\n\n# Define the input tensor\ninput_tensor = Input(shape=(None, None, 1408))  # Replace 'channels' with the actual number\n\n# Create an instance of your custom layer\nattention_layer = CAM()\n\n# Apply your custom layer\noutput_tensor = attention_layer(input_tensor)\n\n# Build the model\nmodel = Model(inputs=input_tensor, outputs=output_tensor)\n\n# Summary of the model to see all parameters including those from PAM\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:06:31.768490Z","iopub.execute_input":"2024-04-27T15:06:31.768895Z","iopub.status.idle":"2024-04-27T15:06:31.799098Z","shell.execute_reply.started":"2024-04-27T15:06:31.768867Z","shell.execute_reply":"2024-04-27T15:06:31.798317Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n│                                 │ \u001b[38;5;34m1408\u001b[0m)                  │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cam_1 (\u001b[38;5;33mCAM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │             \u001b[38;5;34m1\u001b[0m │\n│                                 │ \u001b[38;5;34m1408\u001b[0m)                  │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                  │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cam_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CAM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                  │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1\u001b[0m (4.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> (4.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1\u001b[0m (4.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> (4.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"# Total params: 2,478,081 (9.45 MB)\n#  Trainable params: 2,478,081 (9.45 MB)\n#  Non-trainable params: 0 (0.00 B)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#000080\" size=\"+3\">3. Unit testing</font>\n","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"amber\" size=\"+2\">3.1 Shape testing</font>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras import layers\n\ndef test_cam_shape(input_shape):\n    \"\"\"\n    Tests whether the CAM layer retains the same input and output shape.\n    \n    Args:\n    input_shape (tuple): The shape of the input tensor to test, excluding batch size.\n    \n    Returns:\n    bool: True if the shape test passes, False otherwise.\n    \"\"\"\n    # Create a random tensor with the specified shape\n    input_tensor = tf.random.normal([1] + list(input_shape))\n\n    # Initialize the PAM layer\n    cam_layer = CAM()\n\n    # Get the output from the PAM layer\n    output_tensor = cam_layer(input_tensor)\n\n    # Check if the output shape matches the input shape\n    if input_tensor.shape == output_tensor.shape:\n        print(\"Shape Test Passed: Input shape and output shape are the same.\")\n        return True\n    else:\n        print(\"Shape Test Failed: Output shape does not match input shape.\")\n        return False\n\n# Example usage\ntest_cam_shape((128, 128, 32))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:06:36.156548Z","iopub.execute_input":"2024-04-27T15:06:36.157036Z","iopub.status.idle":"2024-04-27T15:06:36.302475Z","shell.execute_reply.started":"2024-04-27T15:06:36.157003Z","shell.execute_reply":"2024-04-27T15:06:36.301355Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Shape Test Passed: Input shape and output shape are the same.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"### <font color=\"amber\" size=\"+2\">3.2 Functionality testing</font>","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef create_patterned_input(input_shape, pattern_size=(2, 2)):\n    \"\"\"\n    Creates a test input tensor with zeros and a specific pattern in the center.\n    \n    Args:\n    input_shape (tuple): The shape of the input tensor, excluding batch size.\n    pattern_size (tuple): The size of the square pattern to be placed in the center.\n    \n    Returns:\n    tf.Tensor: The created input tensor with a pattern.\n    \"\"\"\n    # Full zeros tensor\n    base_input = tf.zeros([1] + list(input_shape), dtype=tf.float32)\n    \n    # Calculate the start indices for the pattern\n    start_idx_h = input_shape[0] // 2 - pattern_size[0] // 2\n    start_idx_w = input_shape[1] // 2 - pattern_size[1] // 2\n\n    # Create indices for updates\n    indices = []\n    updates = []\n    for i in range(pattern_size[0]):\n        for j in range(pattern_size[1]):\n            for k in range(input_shape[2]):\n                indices.append([0, start_idx_h + i, start_idx_w + j, k])\n                updates.append(1.0)\n\n    # Convert lists to tensors\n    indices = tf.constant(indices, dtype=tf.int32)\n    updates = tf.constant(updates, dtype=tf.float32)\n\n    # Update the base input tensor with a pattern\n    pattern_input = tf.tensor_scatter_nd_update(base_input, indices, updates)\n    return pattern_input\n\ndef test_cam_functionality(input_shape):\n    \"\"\"\n    Tests the functionality of the CAM layer to ensure it alters the input tensor.\n    \n    Args:\n    input_shape (tuple): The shape of the input tensor to test, excluding batch size.\n    \n    Returns:\n    bool: True if the functionality test passes, False otherwise.\n    \"\"\"\n    # Create a controlled test input with a specific pattern\n    test_input = create_patterned_input(input_shape, pattern_size=(1, 1))\n\n    # Initialize the PAM layer\n    cam_layer = CAM(scale_gamma_initializer='ones')\n\n    # Get the output from the PAM layer\n    output_tensor = cam_layer(test_input)\n\n    # Calculate mean of the input and output tensors\n    input_mean = tf.reduce_mean(test_input)\n    output_mean = tf.reduce_mean(output_tensor)\n\n    # Check if there is a statistical difference between the input and output\n    if not tf.math.equal(input_mean, output_mean):\n        print(\"Functionality Test Passed: Output is statistically different from the input.\")\n        return True\n    else:\n        print(\"Functionality Test Failed: Output is statistically the same as the input.\")\n        return False\n\n# Example usage\ntest_cam_functionality((2, 20, 1408))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:06:38.932524Z","iopub.execute_input":"2024-04-27T15:06:38.932937Z","iopub.status.idle":"2024-04-27T15:06:38.997563Z","shell.execute_reply.started":"2024-04-27T15:06:38.932907Z","shell.execute_reply":"2024-04-27T15:06:38.996430Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Functionality Test Passed: Output is statistically different from the input.\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"## Combined","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    from keras.models import Model\n    from keras.layers import Input\n    import keras\n\n    # Define the input tensor\n    # input_tensor = Input(shape=(64, 640, 1408))\n    input_tensor = Input(shape=(None, None, 1408))\n\n    # Create an instance of your custom layer\n    attention_layer = CAM()\n\n    # Apply your custom layer\n    output_tensor = attention_layer(input_tensor)\n\n    # Build the model\n    model = Model(inputs=input_tensor, outputs=output_tensor)\n\n    # Summary of the model to see all parameters including those from PAM\n    print(model.summary())\n    \n    print(f\"\\nPerforming unit testing:\")\n    ## 2. Unit testing\n    ### 2.1 shape testing\n    test_cam_shape((128, 128, 32))\n    \n    ### 2.2 Functionality testing\n    test_cam_functionality((2, 20, 1408))","metadata":{"execution":{"iopub.status.busy":"2024-04-27T15:07:02.182431Z","iopub.execute_input":"2024-04-27T15:07:02.182894Z","iopub.status.idle":"2024-04-27T15:07:02.265715Z","shell.execute_reply.started":"2024-04-27T15:07:02.182861Z","shell.execute_reply":"2024-04-27T15:07:02.264515Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n│                                 │ \u001b[38;5;34m1408\u001b[0m)                  │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cam_4 (\u001b[38;5;33mCAM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │             \u001b[38;5;34m1\u001b[0m │\n│                                 │ \u001b[38;5;34m1408\u001b[0m)                  │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                  │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ cam_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CAM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> │\n│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                  │               │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1\u001b[0m (4.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> (4.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1\u001b[0m (4.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1</span> (4.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n\nPerforming unit testing:\nShape Test Passed: Input shape and output shape are the same.\nFunctionality Test Passed: Output is statistically different from the input.\n","output_type":"stream"}]}]}